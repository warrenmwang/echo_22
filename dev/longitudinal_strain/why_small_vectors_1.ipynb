{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57a63b43-a7af-4b70-ad65-a17926f91d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Original_Pretrained_R2plus1DMotionSegNet.pth\"\n",
    "\n",
    "# model_name = \"dropout_v2_0_25_R2plus1DMotionSegNet.pth\"\n",
    "# model_name = \"dropout_v3_0_10_R2plus1DMotionSegNet.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "951797d1-6f90-43ec-8c8c-ff1aedd619b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wang/workspace/JupyterNoteBooksAll/fully-automated-multi-heartbeat-echocardiography-video-segmentation-and-motion-tracking\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../..\")\n",
    "print(os.getcwd())\n",
    "\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "import SimpleITK as itk\n",
    "from LabelFusion.wrapper import fuse_images\n",
    "\n",
    "import echonet\n",
    "from echonet.datasets import Echo\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models.video import r2plus1d_18\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "from src.utils.torch_utils import TransformDataset, torch_collate\n",
    "from src.utils.echo_utils import get2dPucks\n",
    "from src.utils.camus_validate import cleanupSegmentation\n",
    "from src.transform_utils import generate_2dmotion_field\n",
    "from src.visualization_utils import categorical_dice\n",
    "from src.loss_functions import huber_loss, convert_to_1hot, convert_to_1hot_tensor\n",
    "from src.echonet_dataset import EDESpairs, EchoNetDynamicDataset\n",
    "\n",
    "from src.model.R2plus1D_18_MotionNet import R2plus1D_18_MotionNet\n",
    "\n",
    "# v2 dropout (in place before motion heads, forgot to define in forward pass function, but still saw diff, weird.)\n",
    "from src.model.dropout_v2_0_00_R2plus1D_18_MotionNet import dropout_v2_0_00_R2plus1D_18_MotionNet\n",
    "from src.model.dropout_v2_0_10_R2plus1D_18_MotionNet import dropout_v2_0_10_R2plus1D_18_MotionNet\n",
    "from src.model.dropout_v2_0_25_R2plus1D_18_MotionNet import dropout_v2_0_25_R2plus1D_18_MotionNet\n",
    "from src.model.dropout_v2_0_50_R2plus1D_18_MotionNet import dropout_v2_0_50_R2plus1D_18_MotionNet\n",
    "from src.model.dropout_v2_0_75_R2plus1D_18_MotionNet import dropout_v2_0_75_R2plus1D_18_MotionNet\n",
    "# v3 dropout (one dropout layer defined in forward pass func, this should've been the correct way to do it.)\n",
    "from src.model.dropout_v3_0_00_R2plus1D_18_MotionNet import dropout_v3_0_00_R2plus1D_18_MotionNet\n",
    "from src.model.dropout_v3_0_10_R2plus1D_18_MotionNet import dropout_v3_0_10_R2plus1D_18_MotionNet\n",
    "from src.model.dropout_v3_0_25_R2plus1D_18_MotionNet import dropout_v3_0_25_R2plus1D_18_MotionNet\n",
    "from src.model.dropout_v3_0_50_R2plus1D_18_MotionNet import dropout_v3_0_50_R2plus1D_18_MotionNet\n",
    "from src.model.dropout_v3_0_75_R2plus1D_18_MotionNet import dropout_v3_0_75_R2plus1D_18_MotionNet\n",
    "# v4 dropout (4 dropout layers in different places in the forward func, I'm going to guess more \"generalizable\")\n",
    "from src.model.dropout_v4_0_00_R2plus1D_18_MotionNet import dropout_v4_0_00_R2plus1D_18_MotionNet\n",
    "from src.model.dropout_v4_0_10_R2plus1D_18_MotionNet import dropout_v4_0_10_R2plus1D_18_MotionNet\n",
    "from src.model.dropout_v4_0_25_R2plus1D_18_MotionNet import dropout_v4_0_25_R2plus1D_18_MotionNet\n",
    "from src.model.dropout_v4_0_50_R2plus1D_18_MotionNet import dropout_v4_0_50_R2plus1D_18_MotionNet\n",
    "from src.model.dropout_v4_0_75_R2plus1D_18_MotionNet import dropout_v4_0_75_R2plus1D_18_MotionNet\n",
    "\n",
    "# for finding lv seg borders\n",
    "import cv2 as cv\n",
    "\n",
    "# for storing vector snapshots\n",
    "import copy\n",
    "\n",
    "# from src.visualization_utils import categorical_dice\n",
    "\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "tic, toc = (time.time, time.time)\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8b331b1-a7f7-41a1-911f-af222b4b5e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00, 13.37it/s]\n"
     ]
    }
   ],
   "source": [
    "epoch = 1\n",
    "batch_size = 4\n",
    "num_workers = max(4, cpu_count()//2)\n",
    "\n",
    "def worker_init_fn_valid(worker_id):                                                          \n",
    "    np.random.seed(np.random.get_state()[1][0] + worker_id)\n",
    "    \n",
    "\n",
    "def worker_init_fn(worker_id):\n",
    "    # See here: https://pytorch.org/docs/stable/notes/randomness.html#dataloader\n",
    "    # and the original post of the problem: https://github.com/pytorch/pytorch/issues/5059#issuecomment-817373837\n",
    "    worker_seed = torch.initial_seed() % 2 ** 32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "\n",
    "def permuter(list1, list2):\n",
    "    for i1 in list1:\n",
    "        for i2 in list2:\n",
    "            yield (i1, i2)\n",
    "            \n",
    "\n",
    "param_trainLoader = {'collate_fn': torch_collate,\n",
    "                     'batch_size': batch_size,\n",
    "                     'num_workers': max(4, cpu_count()//2),\n",
    "                     'worker_init_fn': worker_init_fn}\n",
    "\n",
    "param_testLoader = {'collate_fn': torch_collate,\n",
    "                    'batch_size': batch_size,\n",
    "                    'shuffle': False,\n",
    "                    'num_workers': max(4, cpu_count()//2),\n",
    "                    'worker_init_fn': worker_init_fn}\n",
    "\n",
    "paramLoader = {'train': param_trainLoader,\n",
    "               'valid': param_testLoader,\n",
    "               'test':  param_testLoader}\n",
    "\n",
    "\n",
    "with open(\"fold_indexes/stanford_valid_sampled_indices\", \"rb\") as infile:\n",
    "    valid_mask = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "# test_dataset = EchoNetDynamicDataset(split='test', clip_length=\"full\", raise_for_es_ed=False, period=1)\n",
    "\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, \n",
    "#                               num_workers=num_workers,\n",
    "#                               shuffle=False, pin_memory=(\"cuda\"),\n",
    "#                               worker_init_fn=worker_init_fn_valid )\n",
    "\n",
    "valid_dataset = EchoNetDynamicDataset(split='val', subset_indices=valid_mask, period=1)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, \n",
    "                              num_workers=num_workers,\n",
    "                              shuffle=False, pin_memory=(\"cuda\"),\n",
    "                              worker_init_fn=worker_init_fn_valid\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "901c299e-d567-4816-bc62-d7888157605b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_loader = valid_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a11fc7-8069-4339-9efb-daad08f8f79e",
   "metadata": {},
   "source": [
    "## When using the `test_dataset` to create the dataloader I run into a `RuntimeError: stack expects each tensor to be equal size` bc we have different length videos\n",
    "## I don't know what Yida did to solve this problem for validating the model using the validation data split, but I will simply use the validation data split and put that into a dataloader and then feed that into the model\n",
    "## for the purpose of figuring out what the motion tracking is doing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66f03dc8-2748-4dee-9571-214225d99353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original_Pretrained_R2plus1DMotionSegNet.pth has 31575731 parameters.\n"
     ]
    }
   ],
   "source": [
    "model_save_path = f\"save_models/{model_name}\"\n",
    "    \n",
    "if model_name == 'Original_Pretrained_R2plus1DMotionSegNet.pth':\n",
    "    model_template_obj = R2plus1D_18_MotionNet()\n",
    "elif model_name == 'dropout_v2_0_00_R2plus1DMotionSegNet.pth':\n",
    "    model_template_obj = dropout_v2_0_00_R2plus1D_18_MotionNet()\n",
    "elif model_name == 'dropout_v2_0_10_R2plus1DMotionSegNet.pth':\n",
    "    model_template_obj = dropout_v2_0_10_R2plus1D_18_MotionNet()\n",
    "elif model_name == 'dropout_v2_0_25_R2plus1DMotionSegNet.pth':\n",
    "    model_template_obj = dropout_v2_0_25_R2plus1D_18_MotionNet()\n",
    "\n",
    "\n",
    "elif model_name == \"dropout_v3_0_00_R2plus1DMotionSegNet.pth\":\n",
    "    model_template_obj = dropout_v3_0_00_R2plus1D_18_MotionNet()\n",
    "elif model_name == \"dropout_v3_0_10_R2plus1DMotionSegNet.pth\":\n",
    "    model_template_obj = dropout_v3_0_10_R2plus1D_18_MotionNet()\n",
    "elif model_name == \"dropout_v3_0_25_R2plus1DMotionSegNet.pth\":\n",
    "    model_template_obj = dropout_v3_0_25_R2plus1D_18_MotionNet()\n",
    "elif model_name == \"dropout_v4_0_00_R2plus1DMotionSegNet.pth\":\n",
    "    model_template_obj = dropout_v4_0_00_R2plus1D_18_MotionNet()\n",
    "elif model_name == \"dropout_v4_0_10_R2plus1DMotionSegNet.pth\":\n",
    "    model_template_obj = dropout_v4_0_10_R2plus1D_18_MotionNet()\n",
    "elif model_name == \"dropout_v4_0_25_R2plus1DMotionSegNet.pth\":\n",
    "    model_template_obj = dropout_v4_0_25_R2plus1D_18_MotionNet()\n",
    "\n",
    "\n",
    "model = torch.nn.DataParallel(model_template_obj)\n",
    "\n",
    "model.to(\"cuda\")\n",
    "torch.cuda.empty_cache()\n",
    "model.load_state_dict(torch.load(model_save_path)[\"model\"])\n",
    "print(f'{model_name} has {sum(p.numel() for p in model.parameters() if p.requires_grad)} parameters.')\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4445d0b7-50b6-4d38-950c-e19ceef22ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.strain import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c7ed952-360c-45e5-9284-ac6903d9bdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b287a4-7707-48ad-ab97-a7d4d01a3dd2",
   "metadata": {},
   "source": [
    "### We want to look at how the motion tracking is changing the frames, so let's capture all those frames in a dict/hashmasp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c28c5929-1608-4eb7-a3da-d8e0638549e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_to_study = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62f21905-e141-41ee-9ba6-5dbbd675c5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    \"\"\"\n",
    "        Dice loss\n",
    "        See here: https://www.kaggle.com/bigironsphere/loss-function-library-keras-pytorch?scriptVersionId=68471013&cellId=4\n",
    "    \"\"\"\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        inputs = inputs.reshape(-1)\n",
    "        targets = targets.reshape(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()                            \n",
    "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
    "        \n",
    "        return 1 - dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70e6b792-c0c6-4624-8b0d-f006e335d388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_2dmotion_field(x, offset):\n",
    "    # Qin's code for joint_motion_seg learning works fine on our purpose too\n",
    "    # Same idea https://discuss.pytorch.org/t/warp-video-frame-from-optical-flow/6013/5\n",
    "    x_shape = x.size()\n",
    "    grid_w, grid_h = torch.meshgrid([torch.linspace(-1, 1, x_shape[2]), torch.linspace(-1, 1, x_shape[3])])  # (h, w)\n",
    "    grid_w = grid_w.cuda().float()\n",
    "    grid_h = grid_h.cuda().float()\n",
    "\n",
    "    grid_w = nn.Parameter(grid_w, requires_grad=False)\n",
    "    grid_h = nn.Parameter(grid_h, requires_grad=False)\n",
    "\n",
    "    offset_h, offset_w = torch.split(offset, 1, 1)\n",
    "    offset_w = offset_w.contiguous().view(-1, int(x_shape[2]), int(x_shape[3]))  # (b*c, h, w)\n",
    "    offset_h = offset_h.contiguous().view(-1, int(x_shape[2]), int(x_shape[3]))  # (b*c, h, w)\n",
    "\n",
    "    offset_w = grid_w + offset_w\n",
    "    offset_h = grid_h + offset_h\n",
    "    \n",
    "    offsets = torch.stack((offset_h, offset_w), 3)\n",
    "\n",
    "    return offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bd79a85-883c-4cef-9b78-b80de18dd0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def motion_seg_loss(label_ed, label_es, ed_index, es_index, motion_output, seg_softmax, \n",
    "                    start=0, end=32, seg_criterion=DiceLoss()):\n",
    "    \"\"\"\n",
    "        SGS loss that spatially transform the true ED and true ES fully forward to the end of video\n",
    "        and backward to the beginning. Then, compare the forward and backward transformed pseudo labels with\n",
    "        segmentation at all frames.\n",
    "    \"\"\"\n",
    "    flow_source = convert_to_1hot(label_ed, 2)\n",
    "    loss_forward = 0\n",
    "    OTS_loss = 0\n",
    "    OTS_criterion = DiceLoss()\n",
    "    \n",
    "    global frames_to_study\n",
    "    \n",
    "    frames_to_study['one hot label_ed'] = flow_source\n",
    "    \n",
    "    # Forward from ed to the end of video\n",
    "    print('Forward from ed to the end of video')\n",
    "    frames_to_study['Forward from ed to the end of video'] = {}\n",
    "    frames_to_study['Forward from ed to the end of video']['flow_sources'] = []\n",
    "    frames_to_study['Forward from ed to the end of video']['motion_fields'] = []\n",
    "    frames_to_study['Forward from ed to the end of video']['forward_motions'] = []\n",
    "\n",
    "    \n",
    "    for frame_index in range(ed_index, end - 1):\n",
    "        forward_motion = motion_output[:, :2, frame_index,...]\n",
    "        motion_field = generate_2dmotion_field(flow_source, forward_motion)\n",
    "        next_label = F.grid_sample(flow_source, motion_field, align_corners=False, mode=\"bilinear\", padding_mode='border')\n",
    "        \n",
    "        if frame_index == (es_index - 1):\n",
    "            one_hot_ES = convert_to_1hot(label_es, 2)\n",
    "            OTS_loss += OTS_criterion(next_label, one_hot_ES)\n",
    "        else:\n",
    "            loss_forward += seg_criterion(seg_softmax[:, :, frame_index + 1, ...], next_label)\n",
    "        flow_source = next_label\n",
    "        \n",
    "        frames_to_study['Forward from ed to the end of video']['forward_motions'].append([frame_index, forward_motion])\n",
    "        frames_to_study['Forward from ed to the end of video']['motion_fields'].append([frame_index, motion_field])\n",
    "        frames_to_study['Forward from ed to the end of video']['flow_sources'].append([frame_index, flow_source])\n",
    "        \n",
    "    # Forward from es to the end of video\n",
    "    frames_to_study['Forward from es to the end of video'] = []\n",
    "    print('Forward from es to the end of video')\n",
    "    flow_source = convert_to_1hot(label_es, 2)\n",
    "    for frame_index in range(es_index, end - 1):\n",
    "        forward_motion = motion_output[:, :2, frame_index,...]\n",
    "        motion_field = generate_2dmotion_field(flow_source, forward_motion)\n",
    "        next_label = F.grid_sample(flow_source, motion_field, align_corners=False, mode=\"bilinear\", padding_mode='border')\n",
    "\n",
    "        loss_forward += seg_criterion(seg_softmax[:, :, frame_index + 1, ...], next_label)\n",
    "        flow_source = next_label\n",
    "        \n",
    "        \n",
    "        frames_to_study['Forward from es to the end of video'].append([frame_index, flow_source])\n",
    "\n",
    "        \n",
    "    flow_source = convert_to_1hot(label_es, 2)\n",
    "    loss_backward = 0\n",
    "    \n",
    "    frames_to_study['one hot label_es'] = flow_source\n",
    "    \n",
    "    # Backward from es to the beginning of video\n",
    "    frames_to_study['Backward from es to the beginning of video'] = []\n",
    "    print('Backward from es to the beginning of video')\n",
    "\n",
    "    for frame_index in range(es_index, start, -1):\n",
    "        backward_motion = motion_output[:, 2:, frame_index,...]\n",
    "        motion_field = generate_2dmotion_field(flow_source, backward_motion)\n",
    "        next_label = F.grid_sample(flow_source, motion_field, align_corners=False, mode=\"bilinear\", padding_mode='border')\n",
    "        \n",
    "        if frame_index == ed_index + 1:\n",
    "            one_hot_ED = convert_to_1hot(label_ed, 2)\n",
    "            OTS_loss += OTS_criterion(next_label, one_hot_ED)\n",
    "        else:\n",
    "            loss_backward += seg_criterion(seg_softmax[:, :, frame_index - 1, ...], next_label)\n",
    "        flow_source = next_label\n",
    "        \n",
    "        frames_to_study['Backward from es to the beginning of video'].append([frame_index, flow_source])\n",
    "    \n",
    "    \n",
    "    flow_source = convert_to_1hot(label_ed, 2)\n",
    "    \n",
    "    \n",
    "    # Backward from ed to the beginning of video\n",
    "    frames_to_study['Backward from ed to the beginning of video'] = []\n",
    "    print('Backward from ed to the beginning of video')\n",
    "\n",
    "    \n",
    "    for frame_index in range(ed_index, start, -1):\n",
    "        backward_motion = motion_output[:, 2:, frame_index,...]\n",
    "        motion_field = generate_2dmotion_field(flow_source, backward_motion)\n",
    "        next_label = F.grid_sample(flow_source, motion_field, align_corners=False, mode=\"bilinear\", padding_mode='border')\n",
    "        \n",
    "        loss_backward += seg_criterion(seg_softmax[:, :, frame_index - 1, ...], next_label)\n",
    "        flow_source = next_label\n",
    "        \n",
    "        frames_to_study['Backward from ed to the beginning of video'].append([frame_index, flow_source])\n",
    "\n",
    "        \n",
    "    # Averaging the resulting dice\n",
    "    flow_loss = (loss_forward + loss_backward) / ((motion_output.shape[2] - 2) * 2)\n",
    "    OTS_loss = OTS_loss / 2 \n",
    "    \n",
    "    return flow_loss, OTS_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9936a29-c78e-4ea0-84ab-3af87adebbbf",
   "metadata": {},
   "source": [
    "## apply the test function to the fully trained model and see what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8dde5cbb-950f-4509-b6eb-4b1f0007acbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# altered from the original test function, removed the param optimizer bc I don't see it being used\n",
    "def test(epoch, test_loader, model):\n",
    "    \n",
    "    global frames_to_study\n",
    "    \n",
    "    model.eval()\n",
    "    epoch_loss = []\n",
    "    ed_lv_dice = 0\n",
    "    es_lv_dice = 0\n",
    "    \n",
    "    for batch_idx, batch in enumerate(test_loader, 1):\n",
    "        filename, EF, es_clip_index, ed_clip_index, es_index, ed_index, es_frame, ed_frame, es_label, ed_label = batch[1]\n",
    "        with torch.no_grad():\n",
    "            video_clips = torch.Tensor(batch[0])\n",
    "            video_clips = video_clips.type(Tensor)\n",
    "\n",
    "        # Get the motion tracking output from the motion tracking head using the feature map\n",
    "        segmentation_output, motion_output = model(video_clips)\n",
    "        \n",
    "        frames_to_study['raw_seg_out'] = segmentation_output\n",
    "        frames_to_study['raw_motion_out'] = motion_output\n",
    "        \n",
    "        frames_to_study['ed_index'] = ed_index\n",
    "        frames_to_study['es_index'] = es_index\n",
    "        \n",
    "        frames_to_study['delta_ed_es'] = es_index - ed_index\n",
    "        frames_to_study['filename'] = filename\n",
    "        \n",
    "        loss = 0\n",
    "        deform_loss = deformation_motion_loss(video_clips, motion_output)\n",
    "        loss += deform_loss\n",
    "\n",
    "        segmentation_loss = 0\n",
    "        motion_loss = 0\n",
    "        print(f'for i in range(video_clips.shape[0]={video_clips.shape[0]}')\n",
    "        for i in range(video_clips.shape[0]):\n",
    "            print(f'i={i}')\n",
    "            label_ed = np.expand_dims(ed_label.numpy(), 1).astype(\"int\")\n",
    "            label_es = np.expand_dims(es_label.numpy(), 1).astype(\"int\")\n",
    "\n",
    "            label_ed = label_ed[i]\n",
    "            label_es = label_es[i]\n",
    "\n",
    "            label_ed = np.expand_dims(label_ed, 0)\n",
    "            label_es = np.expand_dims(label_es, 0)\n",
    "\n",
    "            motion_one_output = motion_output[i].unsqueeze(0)\n",
    "            segmentation_one_output = segmentation_output[i].unsqueeze(0)\n",
    "\n",
    "            ed_one_index = ed_clip_index[i]\n",
    "            es_one_index = es_clip_index[i]\n",
    "\n",
    "            print('Enter: motion_seg_loss')\n",
    "            segmentation_one_loss, motion_one_loss = motion_seg_loss(label_ed, label_es, \n",
    "                                                                     ed_one_index, es_one_index, \n",
    "                                                                     motion_one_output, segmentation_one_output, \n",
    "                                                                     0, video_clips.shape[2], \n",
    "                                                                     F.binary_cross_entropy_with_logits)\n",
    "            print('Leave: motion_seg_loss')\n",
    "            segmentation_loss += segmentation_one_loss\n",
    "            motion_loss += motion_one_loss\n",
    "            \n",
    "            frames_to_study['segmentation_loss'] = segmentation_loss\n",
    "            frames_to_study['motion_loss'] = motion_loss\n",
    "            \n",
    "            break # just do one iteration\n",
    "            \n",
    "        return # ignore other stuff, just focus on the loss that uses the motion tracking.\n",
    "            \n",
    "        loss += (segmentation_loss / video_clips.shape[0])\n",
    "        loss += (motion_loss / video_clips.shape[0])\n",
    "        \n",
    "        ed_segmentations = torch.Tensor([]).type(Tensor)\n",
    "        es_segmentations = torch.Tensor([]).type(Tensor)\n",
    "        for i in range(len(ed_clip_index)):\n",
    "            ed_one_index = ed_clip_index[i]\n",
    "            es_one_index = es_clip_index[i]\n",
    "            \n",
    "            ed_seg = segmentation_output[i, :, ed_one_index].unsqueeze(0)\n",
    "            ed_segmentations = torch.cat([ed_segmentations, ed_seg])\n",
    "            \n",
    "            es_seg = segmentation_output[i, :, es_one_index].unsqueeze(0)\n",
    "            es_segmentations = torch.cat([es_segmentations, es_seg])\n",
    "            \n",
    "            \n",
    "        ed_es_seg_loss = 0\n",
    "        ed_es_seg_loss += F.binary_cross_entropy_with_logits(ed_segmentations, \n",
    "                                                             convert_to_1hot(np.expand_dims(ed_label.numpy().astype(\"int\"), 1), 2), \n",
    "                                                             reduction=\"mean\") \n",
    "        \n",
    "        ed_es_seg_loss += F.binary_cross_entropy_with_logits(es_segmentations, \n",
    "                                                             convert_to_1hot(np.expand_dims(es_label.numpy().astype(\"int\"), 1), 2), \n",
    "                                                             reduction=\"mean\") \n",
    "        ed_es_seg_loss /= 2\n",
    "        \n",
    "        loss += ed_es_seg_loss\n",
    "        \n",
    "        epoch_loss.append(loss.item())\n",
    "        \n",
    "        ed_segmentation_argmax = torch.argmax(ed_segmentations, 1).cpu().detach().numpy()\n",
    "        es_segmentation_argmax = torch.argmax(es_segmentations, 1).cpu().detach().numpy()\n",
    "        \n",
    "        ed_lv_dice += categorical_dice(ed_segmentation_argmax, ed_label.numpy(), 1)\n",
    "        es_lv_dice += categorical_dice(es_segmentation_argmax, es_label.numpy(), 1)\n",
    "    \n",
    "    print(\"-\" * 30 + \"Validation\" + \"-\" * 30)\n",
    "    print(\"\\nED LV: {:.3f}\".format(ed_lv_dice / batch_idx))\n",
    "    print(\"ES LV: {:.3f}\".format(es_lv_dice / batch_idx))\n",
    "        \n",
    "        # Printing the intermediate training statistics\n",
    "        \n",
    "    print('\\nValid set: Average loss: {:.4f}\\n'.format(np.mean(epoch_loss)))\n",
    "    \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5b05f5f-bcc6-4467-b609-d70764a145ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deformation_motion_loss(source_videos, motion_field):\n",
    "    \"\"\"\n",
    "        OTA loss for motion tracking on echocardiographic frames\n",
    "    \"\"\"\n",
    "    mse_criterion = nn.MSELoss()\n",
    "    mse_loss = 0\n",
    "    smooth_loss = 0\n",
    "    \n",
    "    # Deform both forward and backward from beginning to the end of video clip \n",
    "    for index in range(source_videos.shape[2] - 1):\n",
    "        forward_motion = motion_field[:, :2, index,...]\n",
    "        backward_motion = motion_field[:, 2:, index + 1,...]\n",
    "        \n",
    "        grid_forward = generate_2dmotion_field(source_videos[:, :, index,...], forward_motion)\n",
    "        grid_backward = generate_2dmotion_field(source_videos[:, :, index + 1,...], backward_motion)\n",
    "        \n",
    "        pred_image_forward = F.grid_sample(source_videos[:, :, index,...], grid_forward, \n",
    "                                           align_corners=False, padding_mode='border')\n",
    "        pred_image_backward = F.grid_sample(source_videos[:, :, index + 1,...], grid_backward, \n",
    "                                            align_corners=False, padding_mode='border')\n",
    "        \n",
    "        mse_loss += mse_criterion(source_videos[:, :, index + 1,...], pred_image_forward)\n",
    "        mse_loss += mse_criterion(source_videos[:, :, index,...], pred_image_backward)\n",
    "        \n",
    "        smooth_loss += huber_loss(forward_motion)\n",
    "        smooth_loss += huber_loss(backward_motion)\n",
    "    \n",
    "    # Averaging the resulting loss\n",
    "    return (0.005 * smooth_loss + mse_loss) / 2 / (source_videos.shape[2] - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71fbcb18-0893-4bf3-a1cd-106fe1aaa9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor = torch.cuda.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab181599-aad5-4b04-91cd-929133724667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for i in range(video_clips.shape[0]=4\n",
      "i=0\n",
      "Enter: motion_seg_loss\n",
      "Forward from ed to the end of video\n",
      "Forward from es to the end of video\n",
      "Backward from es to the beginning of video\n",
      "Backward from ed to the beginning of video\n",
      "Leave: motion_seg_loss\n"
     ]
    }
   ],
   "source": [
    "epoch_loss = test(epoch, input_data_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f21b60cd-7f15-4053-a5bd-5d2fba7c684a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['raw_seg_out', 'raw_motion_out', 'ed_index', 'es_index', 'delta_ed_es', 'filename', 'one hot label_ed', 'Forward from ed to the end of video', 'Forward from es to the end of video', 'one hot label_es', 'Backward from es to the beginning of video', 'Backward from ed to the beginning of video', 'segmentation_loss', 'motion_loss'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames_to_study.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a9b59af-abc4-4f45-bd95-60116be0d4c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['flow_sources', 'motion_fields', 'forward_motions'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames_to_study['Forward from ed to the end of video'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "550bc985-b7eb-486f-870d-5195d899ed5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_sources = frames_to_study['Forward from ed to the end of video']['flow_sources']\n",
    "motion_fields = frames_to_study['Forward from ed to the end of video']['motion_fields']\n",
    "forward_motions = frames_to_study['Forward from ed to the end of video']['forward_motions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bcab022-7267-422b-96cc-b1a26873e67c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x max: 1.0742830038070679\n",
      "y max: 1.1389724016189575\n",
      "x max: 1.0800244808197021\n",
      "y max: 1.1325665712356567\n",
      "x max: 1.0887891054153442\n",
      "y max: 1.1339367628097534\n",
      "x max: 1.096480369567871\n",
      "y max: 1.13535475730896\n",
      "x max: 1.1033859252929688\n",
      "y max: 1.1385105848312378\n",
      "x max: 1.1101126670837402\n",
      "y max: 1.1422942876815796\n",
      "x max: 1.1168181896209717\n",
      "y max: 1.1439627408981323\n",
      "x max: 1.1230289936065674\n",
      "y max: 1.1418986320495605\n",
      "x max: 1.1248198747634888\n",
      "y max: 1.14451003074646\n",
      "x max: 1.1245288848876953\n",
      "y max: 1.1462773084640503\n",
      "x max: 1.1242375373840332\n",
      "y max: 1.1500093936920166\n",
      "x max: 1.1239099502563477\n",
      "y max: 1.1582103967666626\n",
      "x max: 1.123462200164795\n",
      "y max: 1.1570152044296265\n",
      "x max: 1.1229815483093262\n",
      "y max: 1.1504524946212769\n",
      "x max: 1.1225008964538574\n",
      "y max: 1.1464910507202148\n",
      "x max: 1.1220455169677734\n",
      "y max: 1.148775577545166\n",
      "x max: 1.1216535568237305\n",
      "y max: 1.1498453617095947\n",
      "x max: 1.1212620735168457\n",
      "y max: 1.1498973369598389\n",
      "x max: 1.1191651821136475\n",
      "y max: 1.1461443901062012\n",
      "x max: 1.113687515258789\n",
      "y max: 1.146403193473816\n",
      "x max: 1.1069519519805908\n",
      "y max: 1.1459685564041138\n",
      "x max: 1.099928855895996\n",
      "y max: 1.1462154388427734\n",
      "x max: 1.0941778421401978\n",
      "y max: 1.1457946300506592\n",
      "x max: 1.0900365114212036\n",
      "y max: 1.1420108079910278\n",
      "x max: 1.0856715440750122\n",
      "y max: 1.138878583908081\n",
      "x max: 1.081363320350647\n",
      "y max: 1.137486219406128\n",
      "x max: 1.0787684917449951\n",
      "y max: 1.1382838487625122\n",
      "x max: 1.0719023942947388\n",
      "y max: 1.1285659074783325\n"
     ]
    }
   ],
   "source": [
    "for f in motion_fields:\n",
    "    x = f[1][0]\n",
    "    x = x.view(2, 112, 112)\n",
    "    x = x.cpu().detach().numpy()\n",
    "    # print( np.max( x[0] ) )\n",
    "    # print( np.max( x[1] ) )\n",
    "    print(f'x max: {np.max(x[0])}' )\n",
    "    print(f'y max: {np.max(x[1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa9eeeb1-ef75-4619-9738-b4aafd9adb40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.48600063, -0.4848116 , -0.48362038, ...,  0.73745733,\n",
       "        0.7383232 ,  0.73963827], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(forward_motions[0][1].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff1a4e95-7801-42d5-be31-1d324783d873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow_sources[0][1].cpu().detach().numpy().max(), flow_sources[0][1].cpu().detach().numpy().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a56d39ec-3aed-446a-a204-756ed8c4e0ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.00420061, 0.00479265, 0.01015763, 0.01669312,\n",
       "       0.05337087, 0.05436031, 0.07432395, 0.08455076, 0.09606268,\n",
       "       0.10629258, 0.12370682, 0.12406415, 0.13430212, 0.16751291,\n",
       "       0.19937134, 0.21464539, 0.23225123, 0.26231384, 0.2854619 ,\n",
       "       0.28568137, 0.3020401 , 0.34088135, 0.3417282 , 0.37032318,\n",
       "       0.45506287, 0.45638186, 0.4607026 , 0.47638702, 0.4803009 ,\n",
       "       0.48939514, 0.51060486, 0.5196991 , 0.523613  , 0.5392974 ,\n",
       "       0.54361814, 0.54493713, 0.6296768 , 0.6582718 , 0.65911865,\n",
       "       0.6979599 , 0.71431863, 0.7145381 , 0.73768616, 0.7677488 ,\n",
       "       0.7853546 , 0.80062866, 0.8324871 , 0.86569786, 0.87593585,\n",
       "       0.8762932 , 0.8937074 , 0.90393734, 0.91544926, 0.92567605,\n",
       "       0.94563967, 0.9466291 , 0.9833069 , 0.98984236, 0.99520737,\n",
       "       0.9957994 , 0.99999994, 1.        ], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(flow_sources[0][1].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e6ab2e8-d9ab-4cd7-8e17-b3f941124ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 112, 112)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow_sources[0][1].cpu().detach().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f99881cc-bbcf-4beb-8084-a2d109ab4967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 112)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blah_1 = np.argmax(flow_sources[0][1].cpu().detach().numpy(), axis=1)\n",
    "blah_1 = blah_1[0]\n",
    "blah_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ffc598be-7662-427e-b4ba-fb9f6b2d6563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b42fba820d4431ca98985a8f296ed73",
       "version_major": 2,
       "version_minor": 0
      },
      "image/png": "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",
      "text/html": [
       "\n",
       "            <div style=\"display: inline-block;\">\n",
       "                <div class=\"jupyter-widgets widget-label\" style=\"text-align: center;\">\n",
       "                    Figure\n",
       "                </div>\n",
       "                <img src='data:image/png;base64,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' width=800.0/>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vis_single(blah_1, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d571449-485a-41f3-916b-a72b37d0a5f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0093, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames_to_study['segmentation_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b2fb907-6686-4c94-b6f5-0b839a3ba909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0112, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames_to_study['motion_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1edf2067-ce48-4c31-b0a8-416f4d59a27c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 112, 112)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames_to_study['one hot label_ed'].cpu().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b7410a81-02d4-4695-9274-fd7afd3f2ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_0 = np.argmax(frames_to_study['one hot label_ed'].cpu().numpy()[0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3fa249f-ea17-42c6-8b3e-7dc1937094bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c26410f40ea442d1ac4f69e243b16e87",
       "version_major": 2,
       "version_minor": 0
      },
      "image/png": "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",
      "text/html": [
       "\n",
       "            <div style=\"display: inline-block;\">\n",
       "                <div class=\"jupyter-widgets widget-label\" style=\"text-align: center;\">\n",
       "                    Figure\n",
       "                </div>\n",
       "                <img src='data:image/png;base64,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' width=800.0/>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vis_single(tmp_0, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "235c166e-0420-41df-8cb7-636b7fb1fd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo_0(x):\n",
    "    return np.argmax(x.cpu().detach().numpy()[0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d4448caa-8b59-4a21-802d-937235dc2ade",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-9f3332add610>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mframes_to_study\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Forward from ed to the end of video'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes_to_study\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Forward from ed to the end of video'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "frames_to_study['Forward from ed to the end of video'][0][0], frames_to_study['Forward from ed to the end of video'][0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c15b0e8-b339-4fdb-80bf-a951960eb991",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(frames_to_study['Forward from ed to the end of video'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea904d28-26f1-43fb-bf41-47baf57e48c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_to_study['raw_seg_out'].shape, frames_to_study['raw_motion_out'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1894ce0f-ea3a-45ed-b738-50043e0a61db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the first video\n",
    "raw_motion_out_0 = frames_to_study['raw_motion_out'][0].cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc43e06-3ef7-4701-8b5e-a101df1c08da",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_motion_out_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097b3756-1fca-4ac9-baae-20071bfef475",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(raw_motion_out_0[0, 0, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b38aab9-7a3f-4edf-b8d5-d539ba22a75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, frames_to_study['delta_ed_es'][0].item()):\n",
    "    print( raw_motion_out_0[1][i][40][50] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae5b2fa-0082-4c37-a9a1-a7fb66a23391",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_to_study['ed_index'], frames_to_study['es_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b1296f-0c3f-4d29-bc50-256c8661f5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_to_study['delta_ed_es']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d416af6-aa27-4648-84e1-96af008aab15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(len(frames_to_study['Forward from ed to the end of video'])):\n",
    "    vis_single(foo_0(frames_to_study['Forward from ed to the end of video'][i][1]), cmap='gray', title=f'i={i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761fb1ff-418c-4583-9fbe-3b3708e5fd8f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The motion tracking information here looks different?\n",
    "## What if I just use this motion tracking info right now??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab03d866-6b84-4bb0-8815-5b48466ddfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_single_point_set_from_vectors(ps_vectors):\n",
    "    ''' ps_vectors - (N, ) np array storing vectors with format (x, y, delta_x, delta_y) '''\n",
    "    f, ax = plt.subplots(1, 1, figsize=(4, 5))\n",
    "    x = []\n",
    "    y = []\n",
    "    for v in ps_vectors:\n",
    "        x.append(v.tail_x)\n",
    "        y.append(v.tail_y)\n",
    "    ax.scatter(x, y, marker='.', color='b')\n",
    "    ax.invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4721ce7-9cc4-4618-b7c0-99df3cd994a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_single_point_set(ps):\n",
    "    ''' ps - (N, 2) stored in (x,y)'''\n",
    "    f, ax = plt.subplots(1, 1, figsize=(4, 5))\n",
    "    ax.scatter(ps[:, 0], ps[:, 1], marker='.', color='b')\n",
    "    ax.invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6875512e-9ec6-4578-a39f-96e4a9560f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_whole_point_set(I):\n",
    "    '''\n",
    "    I - (112, 112) whole image segmentation\n",
    "    points - (N, 2) stored in x, y\n",
    "    '''\n",
    "    I = give_boundary_no_basal_plane(I)\n",
    "    points = []\n",
    "    for i in range(I.shape[0]):\n",
    "        for j in range(I.shape[1]):\n",
    "            if I[i][j] == 1:\n",
    "                points.append(np.array([j, i]))\n",
    "    return np.array(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71aa9532-e858-4fed-960a-c70085137fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_point_set_ij_into_xy(ps_ij):\n",
    "    ''' \n",
    "    converts a point set of shape (M, 2) of points in the (i,j) format into \n",
    "    point set of shape (M, 2) of points in the (x,y) format where\n",
    "    x = j\n",
    "    y = i\n",
    "    \n",
    "    input: ps_ij - (M , 2)\n",
    "    output: ps_xy - (M, 2)\n",
    "        \n",
    "    '''\n",
    "    ps_xy = []\n",
    "    for point in ps_ij:\n",
    "        ps_xy.append(np.array([point[1], point[0]]))\n",
    "    return np.array(ps_xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219a9281-8382-4ce6-ae6e-1b7699ea2566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_point_set_xy_into_vectors(ps_xy):\n",
    "    '''\n",
    "    converts a single point set passed in of shape (M, 2) into a np array of vector adts of shape (M, ) \n",
    "    vectors will have x,y with zero magnitudes representing deltas\n",
    "    \n",
    "    assumes the Vector ADT class definition is accessible in global scope\n",
    " \n",
    "    input: ps_xy - (M, 2)\n",
    "    output: ps_vectors - (M, )\n",
    "    '''\n",
    "    ps_vectors = []\n",
    "    for point in ps_xy:\n",
    "        ps_vectors.append(Vector(point[0], point[1], 0, 0))\n",
    "    return np.array(ps_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d676ef81-2b22-4e16-9dc4-2fa95d7cad22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_one_vector_forward_once(v, frame, motion, scale=1.0):\n",
    "    '''\n",
    "    input: \n",
    "        v - vector to warp\n",
    "            should have base values: (x_i, y_j, 0, 0)\n",
    "        frame - frame integer index\n",
    "        motion - motion object of shape (4, 32, 112, 112)\n",
    "    output:\n",
    "        v_new - vector after warped from given frame\n",
    "            base values: (x_i+1, y_j+1, 0, 0)\n",
    "            \n",
    "    frame given determines what motion tracking information to use\n",
    "    as the frame integer value will be used to index motion\n",
    "    '''\n",
    "    # get surrounding vectors forming the unit square\n",
    "    inted_i, inted_j = int(v.tail_y), int(v.tail_x)\n",
    "    surr_vec_tails = [ [inted_i, inted_j],\n",
    "                       [inted_i, inted_j+1],\n",
    "                       [inted_i+1, inted_j],\n",
    "                       [inted_i+1, inted_j+1] ]\n",
    "    \n",
    "    surround_vectors = []\n",
    "\n",
    "    for _ in surr_vec_tails:\n",
    "        i,j = _[0], _[1]\n",
    "        x = j\n",
    "        y = i\n",
    "\n",
    "        forward_x = motion[0][frame][i][j]\n",
    "        forward_y = motion[1][frame][i][j]\n",
    "\n",
    "        surround_vectors.append(Vector(x, y, forward_x, forward_y))\n",
    "        \n",
    "    # convert magnitudes into polar, bilinearly interpolate new vector magnitude in polar\n",
    "    # to the input vector v's tail_x, tail_y, convert back into \n",
    "    # cartesian, apply the warp, clear out conversion value holders\n",
    "    v_new = vector_bilinear_interpolation(vectors=surround_vectors, new_vector=v)\n",
    "    v_new.update_mag_xy_from_conversion()\n",
    "    \n",
    "    v_new.mag_x *= scale\n",
    "    v_new.mag_y *= scale\n",
    "    \n",
    "    v_new.update_tails_from_mags()\n",
    "    \n",
    "    v_new.clear_conversion_mags_xy()\n",
    "    v_new.clear_conversion_mags_rhotheta()\n",
    "    v_new.clear_magnitudes()\n",
    "    \n",
    "    return v_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeeeb1a1-f685-4f08-a9ed-97024637b2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_one_vector_forward_delta_times(v, motion, delta, scale=1.0):\n",
    "    ''' \n",
    "    handles warping forward a single vector specifically delta times and returns the new vector \n",
    "    \n",
    "    input:\n",
    "        v - vector to warp\n",
    "        motion - motion object of shape (4, 32, 112, 112)\n",
    "        delta - integer telling us how many times to warp\n",
    "    '''\n",
    "    for i in range(delta):\n",
    "        v = warp_one_vector_forward_once(v, i, motion, scale)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c4bacb-bb1e-4e8f-8ba6-61f6442481c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_one_point_set_forward_delta_times(ps_vectors, motion, delta, scale=1.0):\n",
    "    '''\n",
    "    input:\n",
    "        ps_vectors - (M, )\n",
    "            input vectors of base values (x_i, y_i, 0, 0)\n",
    "        motion - motion object of shape (4, 32, 112, 112)\n",
    "        delta - integer telling us how many times to warp\n",
    "    output:\n",
    "        ps_vectors_new - (M, )\n",
    "            new vectors of base values (x_i+delta, y_i+delta, 0, 0)\n",
    "                if save_mag flag is False\n",
    "    '''\n",
    "    ps_vectors = copy.deepcopy(ps_vectors)\n",
    "    \n",
    "    ps_vectors_new = []\n",
    "    for v in ps_vectors:\n",
    "        ps_vectors_new.append(warp_one_vector_forward_delta_times(v, motion, delta, scale))\n",
    "    return np.array(ps_vectors_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221daeca-16cc-4ab7-8b4c-37888f79cb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_double_three_point_sets(vectors_dict, title='ED Blue | ES Red'):\n",
    "    '''\n",
    "    vectors_dict - two keys 'ED' and 'ES'\n",
    "        each point to an array of three point sets representing regional points (apical, mid, basal) ... or more depending on N...well it's hardcoded for now\n",
    "    '''\n",
    "    fig, ax = plt.subplots(1,3, figsize=(10,7), sharex = True, sharey = True)\n",
    "    x = []\n",
    "    y = []\n",
    "    for v in vectors_dict['ED'][0]:\n",
    "        x.append(v.tail_x)\n",
    "        y.append(v.tail_y)\n",
    "    ax[0].scatter(x, y, marker='.', color='b', zorder=1)     # ED\n",
    "    \n",
    "    x.clear()\n",
    "    y.clear()\n",
    "    for v in vectors_dict['ES'][0]:\n",
    "        x.append(v.tail_x)\n",
    "        y.append(v.tail_y)\n",
    "    ax[0].scatter(x, y, marker='.', color='r', zorder=2) # ES\n",
    "    ax[0].invert_yaxis()\n",
    "    ax[0].set_title('Apical')\n",
    "\n",
    "    \n",
    "    x.clear()\n",
    "    y.clear()\n",
    "    for v in vectors_dict['ED'][1]:\n",
    "        x.append(v.tail_x)\n",
    "        y.append(v.tail_y)\n",
    "    ax[1].scatter(x, y, marker='.', color='b', zorder=1)    # ED\n",
    "    \n",
    "    x.clear()\n",
    "    y.clear()\n",
    "    for v in vectors_dict['ES'][1]:\n",
    "        x.append(v.tail_x)\n",
    "        y.append(v.tail_y)\n",
    "    ax[1].scatter(x, y, marker='.', color='r', zorder=2)# ES\n",
    "    ax[1].invert_yaxis()\n",
    "    ax[1].set_title('Mid')\n",
    "\n",
    "    \n",
    "    x.clear()\n",
    "    y.clear()\n",
    "    for v in vectors_dict['ED'][2]:\n",
    "        x.append(v.tail_x)\n",
    "        y.append(v.tail_y)\n",
    "    ax[2].scatter(x, y, marker='.', color='b', zorder=1)    # ED\n",
    "    \n",
    "    x.clear()\n",
    "    y.clear()\n",
    "    for v in vectors_dict['ES'][2]:\n",
    "        x.append(v.tail_x)\n",
    "        y.append(v.tail_y)\n",
    "    ax[2].scatter(x, y, marker='.', color='r', zorder=2)# ES\n",
    "    ax[2].invert_yaxis()\n",
    "    ax[2].set_title('Basal')\n",
    "    \n",
    "    fig.suptitle(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9feeb353-f0df-4edc-ae6e-7360437fb9cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2688647-f632-43ac-a3e5-32228b4b9573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fbee61-2723-446a-89c0-a75b973dcfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_ed_es = frames_to_study['delta_ed_es'][0]\n",
    "curr_clip_motions = raw_motion_out_0\n",
    "I = tmp_0\n",
    "N = 3\n",
    "I_regional_point_sets = image_to_regional_point_sets(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4df0aaf-9a6c-483b-8325-92288d6bf057",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_three_point_sets(I_regional_point_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3a7c42-c706-45fd-9b5f-511a58a2e20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "I_ED_and_ES_regional_point_sets_as_vectors = {}\n",
    "I_ED_and_ES_regional_point_sets_as_vectors['ED'] = []\n",
    "I_ED_and_ES_regional_point_sets_as_vectors['ES'] = []\n",
    "\n",
    "\n",
    "for IND in range(N):\n",
    "    ps = I_regional_point_sets[IND]\n",
    "\n",
    "    ps = convert_point_set_ij_into_xy(ps)\n",
    "\n",
    "    ps = convert_point_set_xy_into_vectors(ps)\n",
    "\n",
    "    new_ps = warp_one_point_set_forward_delta_times(ps_vectors = ps, \n",
    "                                           motion = curr_clip_motions,\n",
    "                                           delta = delta_ed_es)\n",
    "\n",
    "    I_ED_and_ES_regional_point_sets_as_vectors['ED'].append(ps)\n",
    "    I_ED_and_ES_regional_point_sets_as_vectors['ES'].append(new_ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e686b48-fada-439e-8802-0083ba1df68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_double_three_point_sets(vectors_dict = I_ED_and_ES_regional_point_sets_as_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f61b38-5f67-4091-a38f-d876feac980d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(I_ED_and_ES_regional_point_sets_as_vectors['ED'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de5c9cc-f65e-4dc2-9320-5dde9db383ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(I_ED_and_ES_regional_point_sets_as_vectors['ES'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ea81b0-5e1e-4368-89fd-501f15086021",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_x_0 = I_ED_and_ES_regional_point_sets_as_vectors['ES'][0][0].tail_x - I_ED_and_ES_regional_point_sets_as_vectors['ED'][0][0].tail_x\n",
    "delta_y_0 = I_ED_and_ES_regional_point_sets_as_vectors['ES'][0][0].tail_y - I_ED_and_ES_regional_point_sets_as_vectors['ED'][0][0].tail_y\n",
    "print(f'delta_x_0: {delta_x_0}\\ndelta_y_0: {delta_y_0}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ec496b-f5e3-499b-8803-1fc4df7baad0",
   "metadata": {},
   "source": [
    "## Let's try warping a single point using the different motion tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c25483-a550-4556-a7ea-4e1b007d9bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_one_vec_multiple_frames(all_vectors):\n",
    "    '''\n",
    "    input: all_vectors - python list of Vector ADTs\n",
    "    '''\n",
    "    \n",
    "    x_tails = []\n",
    "    y_tails = []\n",
    "    x_mags = []\n",
    "    y_mags = []\n",
    "\n",
    "    for v in all_vectors:\n",
    "        x_tails.append(v.tail_x)\n",
    "        y_tails.append(v.tail_y)\n",
    "\n",
    "        x_mags.append(v.mag_x)\n",
    "        y_mags.append(v.mag_y)\n",
    "\n",
    "    # vector field\n",
    "    f, ax = plt.subplots(1,2,figsize=(8, 5))\n",
    "    ax[0].quiver(x_tails, y_tails, x_mags, y_mags, color='k', linewidth=0.7)\n",
    "    ax[0].invert_yaxis()\n",
    "    \n",
    "    # scatter plot, color gradient points\n",
    "    ax[1].scatter(x_tails, y_tails, c=np.linspace(0,1,len(x_tails)))\n",
    "    ax[1].invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde4064b-4ae2-4fb5-bdc6-c9355e3d202c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one vector and show its progression thru time\n",
    "# that means we'll need to keep all of the intermediate vectors of this single point being traversed thru time/frame\n",
    "def foo_1(vector_id_0):\n",
    "    ''' vector_id_0 is Vector '''\n",
    "    multiple_time_snapshots_of_vector_id_0 = []\n",
    "\n",
    "    # vector_id_0 = apical_point_set[0]o\n",
    "\n",
    "    v = vector_id_0 # (x_0, y_0, delta_x_0, delta_y_0)\n",
    "    v.mag_x = curr_clip_motions[0][0][v.tail_y][v.tail_x]\n",
    "    v.mag_y = curr_clip_motions[1][0][v.tail_y][v.tail_x]\n",
    "\n",
    "\n",
    "    multiple_time_snapshots_of_vector_id_0.append(v)\n",
    "\n",
    "\n",
    "\n",
    "    for frame in range(delta_ed_es):\n",
    "        frame += 1\n",
    "\n",
    "        new_vect = copy.deepcopy(multiple_time_snapshots_of_vector_id_0[-1])\n",
    "\n",
    "        new_vect.update_tails_from_mags()\n",
    "\n",
    "        new_vect.clear_magnitudes()\n",
    "        new_vect.clear_conversion_mags_xy()\n",
    "        new_vect.clear_conversion_mags_rhotheta()\n",
    "\n",
    "        # now interpolate to get delta_x_1, delta_y_1\n",
    "        # get surrounding vectors forming the unit square\n",
    "        inted_i, inted_j = int(new_vect.tail_y), int(new_vect.tail_x)\n",
    "        surr_vec_tails = [ [inted_i, inted_j],\n",
    "                           [inted_i, inted_j+1],\n",
    "                           [inted_i+1, inted_j],\n",
    "                           [inted_i+1, inted_j+1] ]\n",
    "\n",
    "        surround_vectors = []\n",
    "\n",
    "        for _ in surr_vec_tails:\n",
    "            i,j = _[0], _[1]\n",
    "            x = j\n",
    "            y = i\n",
    "\n",
    "            forward_x = curr_clip_motions[0][frame][i][j]\n",
    "            forward_y = curr_clip_motions[1][frame][i][j]\n",
    "\n",
    "            surround_vectors.append(Vector(x, y, forward_x, forward_y))\n",
    "\n",
    "        # convert magnitudes into polar, bilinearly interpolate new vector magnitude in polar\n",
    "        # to the input vector v's tail_x, tail_y, convert back into \n",
    "        # cartesian, apply the warp, clear out conversion value holders\n",
    "        v_new = vector_bilinear_interpolation(vectors=surround_vectors, new_vector=new_vect)\n",
    "\n",
    "        v_new.update_mag_xy_from_conversion()\n",
    "\n",
    "        delta_x_1 = v_new.mag_x\n",
    "        delta_y_1 = v_new.mag_y\n",
    "\n",
    "        new_vect.mag_x = delta_x_1\n",
    "        new_vect.mag_y = delta_y_1\n",
    "\n",
    "        multiple_time_snapshots_of_vector_id_0.append(new_vect)\n",
    "        \n",
    "    # last point does not need magnitude as that point should be the point in the ES frame\n",
    "    multiple_time_snapshots_of_vector_id_0[-1].clear_magnitudes()\n",
    "    \n",
    "    return multiple_time_snapshots_of_vector_id_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a174646-0469-47ad-a607-f3fa29699b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_id_0 = Vector(17, 50, 0, 0)\n",
    "\n",
    "multiple_time_snapshots_of_vector_id_0 = foo_1(vector_id_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcb7e61-00d4-4732-93a1-4949fd6ac5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in multiple_time_snapshots_of_vector_id_0:\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c7f4fd-62cc-4ce7-8850-5bd4c4abc3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_one_vec_multiple_frames(multiple_time_snapshots_of_vector_id_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1359fac5-2568-4dc6-a970-039ac1d7ead9",
   "metadata": {},
   "source": [
    "## Why are the vector heads not pointing to vector tails? That's what we should see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bbcf14-85c3-486c-b92f-9b06565b8732",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_1, v_2 = multiple_time_snapshots_of_vector_id_0[0], multiple_time_snapshots_of_vector_id_0[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a255119-2f2d-47ff-b9aa-e8d4c81794e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_2.tail_x == v_1.tail_x + v_1.mag_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602f397a-1954-45a7-876b-e3e149aada0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_2.tail_y == v_1.tail_y + v_1.mag_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c804826-6a0a-471b-a71c-0e3a9200c39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_1.tail_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728051cf-fb1f-413e-9b96-65f80c149c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pos = [v_1.tail_x, v_2.tail_x]\n",
    "y_pos = [v_1.tail_y, v_2.tail_y]\n",
    "x_direct = [v_1.mag_x, v_2.mag_x]\n",
    "y_direct = [v_1.mag_y, v_2.mag_y] \n",
    "\n",
    "plt.figure()\n",
    "plt.quiver(x_pos, y_pos, x_direct, y_direct, angles='xy', scale_units='xy', units='xy', scale=6)\n",
    "# plt.xticks(range(-5,6))\n",
    "# plt.yticks(range(-5,6))\n",
    "plt.show()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58365a19-a755-49da-a328-e42dd123ebf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pos = [0, 1]\n",
    "y_pos = [0, 1]\n",
    "x_direct = [1, 0]\n",
    "y_direct = [1, 0] \n",
    "\n",
    "plt.figure()\n",
    "plt.quiver(x_pos, y_pos, x_direct, y_direct)\n",
    "plt.xticks(range(-5,6))\n",
    "plt.yticks(range(-5,6))\n",
    "plt.show()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae07b959-1712-4a87-93be-ffe8c53aff6a",
   "metadata": {},
   "source": [
    "So it is only the visualization that is off. The scaling of the vis is weird. The vectors are correct looking at the tail values and the delta values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ddb57a-90e5-4964-ac57-876161140f22",
   "metadata": {},
   "source": [
    "## Let's try to warp regional point sets using the \"better\" motion tracking info?\n",
    "## So I use the same procedure that I have created, but just use different motion tracking info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a2409a-71a7-496f-a4cf-b45e11b7c5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "better_motion_tracking = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
