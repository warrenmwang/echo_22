{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3933bf8-188c-46f6-ab8e-6bbfa54fb0c7",
   "metadata": {},
   "source": [
    "# How to do k-fold cross validation?\n",
    "## TODOs:\n",
    "### - split data into your own k folds\n",
    "### - update the training and testing/validating functions to use the k folds in the correct way \n",
    "### - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee38bae4-43be-496b-9222-1c692d610869",
   "metadata": {},
   "source": [
    "## For now, let's load in the original dataset with their given 3 fold split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f301364-4f6a-4057-8121-594578f0ef7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wang/workspace/JupyterNoteBooksAll/fully-automated-multi-heartbeat-echocardiography-video-segmentation-and-motion-tracking\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1fd08a5-6884-4590-9df8-ca0c9304bba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "\n",
    "import echonet\n",
    "from echonet.datasets import Echo\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models.video import r2plus1d_18\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "from src.utils.torch_utils import TransformDataset, torch_collate\n",
    "from src.transform_utils import generate_2dmotion_field\n",
    "from src.loss_functions import huber_loss, convert_to_1hot, convert_to_1hot_tensor\n",
    "from src.model.R2plus1D_18_MotionNet import R2plus1D_18_MotionNet  # ORIGINAL MODEL\n",
    "from src.model.WIP_R2plus1D_18_MotionNet import WIP_R2plus1D_18_MotionNet # WIP MODEL\n",
    "from src.echonet_dataset import EchoNetDynamicDataset\n",
    "from src.clasfv_losses import deformation_motion_loss, motion_seg_loss, DiceLoss, categorical_dice\n",
    "from src.train_test import train, test\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "tic, toc = (time.time, time.time)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce57789b-5264-4fbe-a311-ec01205afa9d",
   "metadata": {},
   "source": [
    "## Now we need to load in data to train a new model\n",
    "### Copy and paste cells below..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3836be81-037a-4987-af80-3ae3f12717ac",
   "metadata": {},
   "source": [
    "### Load the indices of the subset data used for training and validating\n",
    "\n",
    "Subset out our Train and Validation Dataset. We exclude the EchoNet videos with no clinically denoted systolic clip or ED-ES duration > 30 frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de76bf3b-d318-4e07-983f-d9d0b40beea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"fold_indexes/stanford_train_sampled_indices\", \"rb\") as infile:\n",
    "    train_mask = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "with open(\"fold_indexes/stanford_valid_sampled_indices\", \"rb\") as infile:\n",
    "    valid_mask = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649dbd09-9e8d-4717-ac04-61bcf8484ac6",
   "metadata": {},
   "source": [
    "### Set up the training and validating dataset\n",
    "work initialization function is required for generating **random** 32-frame video clip in each training epoch  \n",
    "Failure to initialize the worker will cause the random 32-frame window to be the **same** for a video during every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76d7d17d-0572-43f1-892b-b873c52442e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "num_workers = max(4, cpu_count()//2)\n",
    "\n",
    "def worker_init_fn_valid(worker_id):                                                          \n",
    "    np.random.seed(np.random.get_state()[1][0] + worker_id)\n",
    "    \n",
    "\n",
    "def worker_init_fn(worker_id):\n",
    "    # See here: https://pytorch.org/docs/stable/notes/randomness.html#dataloader\n",
    "    # and the original post of the problem: https://github.com/pytorch/pytorch/issues/5059#issuecomment-817373837\n",
    "    worker_seed = torch.initial_seed() % 2 ** 32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "    \n",
    "\n",
    "def permuter(list1, list2):\n",
    "    for i1 in list1:\n",
    "        for i2 in list2:\n",
    "            yield (i1, i2)\n",
    "            \n",
    "\n",
    "param_trainLoader = {'collate_fn': torch_collate,\n",
    "                     'batch_size': batch_size,\n",
    "                     'num_workers': max(4, cpu_count()//2),\n",
    "                     'worker_init_fn': worker_init_fn}\n",
    "\n",
    "param_testLoader = {'collate_fn': torch_collate,\n",
    "                    'batch_size': batch_size,\n",
    "                    'shuffle': False,\n",
    "                    'num_workers': max(4, cpu_count()//2),\n",
    "                    'worker_init_fn': worker_init_fn}\n",
    "\n",
    "paramLoader = {'train': param_trainLoader,\n",
    "               'valid': param_testLoader,\n",
    "               'test':  param_testLoader}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7cef3f-031b-450a-aff2-e6809838b36e",
   "metadata": {},
   "source": [
    "### Load in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d584b5a2-37cb-4ddd-834d-fae3bee3eae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00, 15.20it/s]\n",
      "100%|██████████| 16/16 [00:01<00:00, 14.30it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_mask' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-781aeaf1c153>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEchoNetDynamicDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvalid_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEchoNetDynamicDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEchoNetDynamicDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# test_dataset = EchoNetDynamicDataset(split='test', clip_length=\"full\", raise_for_es_ed=False, period=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_mask' is not defined"
     ]
    }
   ],
   "source": [
    "train_dataset = EchoNetDynamicDataset(split='train', subset_indices=train_mask, period=1)\n",
    "valid_dataset = EchoNetDynamicDataset(split='val', subset_indices=valid_mask, period=1)\n",
    "test_dataset = EchoNetDynamicDataset(split='test', subset_indices=test_mask, period=1)\n",
    "# test_dataset = EchoNetDynamicDataset(split='test', clip_length=\"full\", raise_for_es_ed=False, period=1)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, \n",
    "                              num_workers=num_workers, \n",
    "                              shuffle=True, pin_memory=(\"cuda\"), \n",
    "                              worker_init_fn=worker_init_fn,\n",
    "                              drop_last=True)\n",
    "\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, \n",
    "                              num_workers=num_workers,\n",
    "                              shuffle=False, pin_memory=(\"cuda\"),\n",
    "                              worker_init_fn=worker_init_fn_valid\n",
    "                             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f1e669-cf14-4c22-9e1f-bad820f80e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'training: {len(train_dataset)}')\n",
    "print(f'validation: {len(valid_dataset)}')\n",
    "print(f'testing: {len(test_dataset)}')\n",
    "print(f'TOTAL: {len(train_dataset) + len(valid_dataset) + len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764c8786-8a75-4eb9-a0ab-afe806da5c9c",
   "metadata": {},
   "source": [
    "#### Well, that's not all 10030 videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456db983-78ab-4f5f-997f-85bf6e6ee8f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
