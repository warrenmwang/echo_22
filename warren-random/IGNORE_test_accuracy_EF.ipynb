{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "anonymous-article",
   "metadata": {},
   "source": [
    "## I want a simple, clear way to see how well my model is doing. Let's compare the Ground Truth EF with ones we can calculate from our Model.\n",
    "\n",
    "We'll try to go through all videos, compute their estimated EF's and see how they compare with the ground truths.\n",
    "\n",
    "I think we'll try to do a Mean Squared Error, and we can also simply just look at the average percentage error:<br>\n",
    "$Y_i$ is the predicted value.<br>\n",
    "$\\hat{Y_i}$ is the expected value.\n",
    "\n",
    "$$ MSE = \\frac{1}{n}\\sum_{i = 1}^n (Y_i - \\hat{Y_i})^2 $$\n",
    "$$ \\% error = \\frac{|\\hat{Y_i} - Y_i|}{\\hat{Y_i}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3bba4a2-7156-4d78-bdfa-0616a44fb0d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-1-42b272d6f93c>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-42b272d6f93c>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    model_name_1 = \"\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "model_name_1 = \"\"\n",
    "model_name_2 = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "downtown-firmware",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wang/workspace/JupyterNoteBooksAll/fully-automated-multi-heartbeat-echocardiography-video-segmentation-and-motion-tracking\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "os.chdir(\"..\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "spatial-minutes",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "\n",
    "import echonet\n",
    "from echonet.datasets import Echo\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models.video import r2plus1d_18\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "from src.utils.torch_utils import TransformDataset, torch_collate\n",
    "from src.utils.echo_utils import get2dPucks\n",
    "from src.utils.camus_validate import cleanupSegmentation\n",
    "from src.transform_utils import generate_2dmotion_field\n",
    "from src.visualization_utils import categorical_dice\n",
    "from src.loss_functions import huber_loss, convert_to_1hot, convert_to_1hot_tensor\n",
    "from src.model.R2plus1D_18_MotionNet import R2plus1D_18_MotionNet\n",
    "from src.echonet_dataset import EchoNetDynamicDataset\n",
    "\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "tic, toc = (time.time, time.time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seventh-michigan",
   "metadata": {},
   "source": [
    "## Load in Test data to validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "contemporary-saying",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "num_workers = max(4, cpu_count()//2)\n",
    "\n",
    "def worker_init_fn_valid(worker_id):                                                          \n",
    "    np.random.seed(np.random.get_state()[1][0] + worker_id)\n",
    "    \n",
    "\n",
    "def worker_init_fn(worker_id):\n",
    "    # See here: https://pytorch.org/docs/stable/notes/randomness.html#dataloader\n",
    "    # and the original post of the problem: https://github.com/pytorch/pytorch/issues/5059#issuecomment-817373837\n",
    "    worker_seed = torch.initial_seed() % 2 ** 32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "    \n",
    "\n",
    "def permuter(list1, list2):\n",
    "    for i1 in list1:\n",
    "        for i2 in list2:\n",
    "            yield (i1, i2)\n",
    "            \n",
    "\n",
    "param_trainLoader = {'collate_fn': torch_collate,\n",
    "                     'batch_size': batch_size,\n",
    "                     'num_workers': max(4, cpu_count()//2),\n",
    "                     'worker_init_fn': worker_init_fn}\n",
    "\n",
    "param_testLoader = {'collate_fn': torch_collate,\n",
    "                    'batch_size': batch_size,\n",
    "                    'shuffle': False,\n",
    "                    'num_workers': max(4, cpu_count()//2),\n",
    "                    'worker_init_fn': worker_init_fn}\n",
    "\n",
    "paramLoader = {'train': param_trainLoader,\n",
    "               'valid': param_testLoader,\n",
    "               'test':  param_testLoader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "damaged-polls",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00, 15.55it/s]\n",
      "100%|██████████| 16/16 [00:01<00:00, 13.84it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(\"fold_indexes/stanford_valid_sampled_indices\", \"rb\") as infile:\n",
    "    valid_mask = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "full_dataset = EchoNetDynamicDataset(split='val', clip_length=\"full\", raise_for_es_ed=False, subset_indices=valid_mask, period=1)\n",
    "test_dataset = EchoNetDynamicDataset(split='test', clip_length=\"full\", raise_for_es_ed=False, period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fallen-theology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vids in test dataset: 1276\n"
     ]
    }
   ],
   "source": [
    "print(\"vids in test dataset:\", len(test_dataset)) # how many videos are in the test dataset\n",
    "\n",
    "test_pat_indeces = [i for i in range(len(test_dataset))] # creates a list of all indeces of test_dataset\n",
    "# print(len(test_pat_index))\n",
    "\n",
    "# print(test_pat_indeces)\n",
    "# video, (filename, EF, es_clip_index, ed_clip_index, es_index, ed_index, es_frame, ed_frame, es_label, ed_label) = test_dataset[test_pat_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "future-precipitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values_for_curr_vid(ind, test_dataset):\n",
    "    video, (filename, GROUND_TRUTH_EF, es_clip_index, ed_clip_index, es_index, ed_index, es_frame, ed_frame, es_label, ed_label) = test_dataset[ind]\n",
    "    return video, (filename, GROUND_TRUTH_EF, es_clip_index, ed_clip_index, es_index, ed_index, es_frame, ed_frame, es_label, ed_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coupled-thursday",
   "metadata": {},
   "source": [
    "## Load in Trained Model to Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "designing-chart",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2+1D MotionNet has 31575731 parameters.\n"
     ]
    }
   ],
   "source": [
    "model_save_path = \"save_models/R2plus1DMotionSegNet_model.pth\"\n",
    "\n",
    "model = torch.nn.DataParallel(R2plus1D_18_MotionNet())\n",
    "model.to(\"cuda\")\n",
    "torch.cuda.empty_cache()\n",
    "model.load_state_dict(torch.load(model_save_path)[\"model\"])\n",
    "print(f'R2+1D MotionNet has {sum(p.numel() for p in model.parameters() if p.requires_grad)} parameters.')\n",
    "\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dramatic-apartment",
   "metadata": {},
   "source": [
    "## Define Funcs to Calculate our Values for Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "built-dealing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_predicted_ef(ed_label, es_label):\n",
    "    # Use the ground true lables to derive the EF\n",
    "    output_ED = ed_label\n",
    "    output_ES = es_label\n",
    "\n",
    "    # Use the Simpson's Monoplane method\n",
    "    length_ed, radius_ed = get2dPucks((output_ED == 1).astype('int'), (1.0, 1.0))\n",
    "    length_es, radius_es = get2dPucks((output_ES == 1).astype('int'), (1.0, 1.0))\n",
    "\n",
    "    edv = np.sum(((np.pi * radius_ed * radius_ed) * length_ed / len(radius_ed)))\n",
    "    esv = np.sum(((np.pi * radius_es * radius_es) * length_es / len(radius_es)))\n",
    "\n",
    "    ef_predicted = (edv - esv) / edv * 100\n",
    "    return ef_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "tamil-rapid",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(video_indeces, test_dataset):\n",
    "    Error_Percentages = []\n",
    "    Predicted_Values = []\n",
    "    Expected_Values = [] \n",
    "    # get predicted and ground truth EF values\n",
    "    for ind in video_indeces:\n",
    "        video, (filename, GROUND_TRUTH_EF, es_clip_index, ed_clip_index, es_index, ed_index, es_frame, ed_frame, es_label, ed_label) = get_values_for_curr_vid(ind, test_dataset)\n",
    "        ef_predicted = compute_predicted_ef(ed_label, es_label)\n",
    "        Predicted_Values.append(ef_predicted)\n",
    "        Expected_Values.append(GROUND_TRUTH_EF)\n",
    "    # compute MSE and error percentages\n",
    "    tmp = []\n",
    "    for pred, exp in zip(Predicted_Values, Expected_Values):\n",
    "        # for MSE\n",
    "        tmp.append((pred - exp) ** 2)\n",
    "        # for error percentages\n",
    "        Error_Percentages.append(abs(exp - pred)/exp)\n",
    "    # finish computing MSE\n",
    "    MSE = (1/len(tmp)) * np.sum(tmp)\n",
    "    \n",
    "    # return values\n",
    "    return MSE, Error_Percentages, Predicted_Values, Expected_Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structural-victim",
   "metadata": {},
   "source": [
    "## Compute, Display, and Save to File the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "declared-stream",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE, Error_Percentages, Predicted_Values, Expected_Values = run(test_pat_indeces, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "plain-seventh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 7.169083941314519\n",
      "Average Error_Percentages: 0.031004062276521215\n"
     ]
    }
   ],
   "source": [
    "print(f'MSE: {MSE}')\n",
    "avg_error_perc = np.sum([(1/len(Error_Percentages) * err) for err in Error_Percentages])\n",
    "print(f\"Average Error_Percentages: {avg_error_perc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "intimate-sapphire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed\tExpected\t% Difference\n",
      "\n",
      "57.10036\t55.95179\t0.02053\n",
      "40.61877\t41.01442\t0.00965\n",
      "50.43640\t50.79472\t0.00705\n",
      "52.61210\t50.63498\t0.03905\n",
      "63.55931\t63.09809\t0.00731\n",
      "59.80891\t58.49444\t0.02247\n",
      "67.73466\t67.38157\t0.00524\n",
      "57.50785\t57.28491\t0.00389\n",
      "58.71777\t59.91861\t0.02004\n"
     ]
    }
   ],
   "source": [
    "print(\"Observed\\tExpected\\t% Difference\\n\")\n",
    "count = 0\n",
    "for pred, exp, per_diff in zip(Predicted_Values, Expected_Values, Error_Percentages):\n",
    "    count += 1\n",
    "    if count == 10:\n",
    "        break\n",
    "    print(f\"{pred:.5f}\\t{exp:.5f}\\t{per_diff:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "sublime-coast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to a file for now.\n",
    "save_filename = \"./warren-random/save_EF-2.txt\"\n",
    "with open(save_filename, \"w\") as file:\n",
    "    file.write(f'Model Name/Path: {model_save_path}\\n')\n",
    "    file.write(\"####### Basic Stats: #######\\n\\n\")\n",
    "    file.write(f'Num of Vids: {len(Expected_Values)}\\n')\n",
    "    file.write(f\"MSE: {MSE}\\n\")\n",
    "    file.write(f\"Average Percentage Error: {avg_error_perc}\\n\")\n",
    "    file.write('####### Observed, Expected, and % Difference #######\\n\\n') \n",
    "    for pred, exp, per_diff in zip(Predicted_Values, Expected_Values, Error_Percentages):\n",
    "        file.write(f\"{pred}\\t{exp}\\t{per_diff}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optical-latter",
   "metadata": {},
   "source": [
    "# FIXME: This is just using numbers from the test dataset itself. The model is not doing anything to compute the Ejection Fraction from how I've written it.\n",
    "\n",
    "## We need to pass in clips to the model, and it will output as according to this single line of code:\n",
    "`segmentation_output, motion_output = model(torch.Tensor(one_clip))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-product",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
